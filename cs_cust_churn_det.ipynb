{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56a17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369d0d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "Info about dataset:\n",
      " None\n",
      "Check first 5 rows:\n",
      "    RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "Summary Statistics:\n",
      "          RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\Churn_Modelling.csv') #load dset\n",
    "\n",
    "print(\"Info about dataset:\\n\", data.info())\n",
    "print(\"Check first 5 rows:\\n\", data.head())\n",
    "print(\"Summary Statistics:\\n\", data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97fc1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "data = pd.get_dummies(data, columns=['Geography'], drop_first=True)\n",
    "\n",
    "X = data.drop('Exited', axis=1)  \n",
    "y = data['Exited']                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4051c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training, testing dset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71402670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models used\n",
    "log_reg = LogisticRegression()\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f57157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Accuracy: 0.811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1607\n",
      "           1       0.55      0.20      0.29       393\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.69      0.58      0.59      2000\n",
      "weighted avg       0.78      0.81      0.77      2000\n",
      "\n",
      "[[1543   64]\n",
      " [ 314   79]]\n"
     ]
    }
   ],
   "source": [
    "#train, evaluate logistic regression\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa43afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "Accuracy: 0.8665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1607\n",
      "           1       0.76      0.46      0.58       393\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.71      0.75      2000\n",
      "weighted avg       0.86      0.87      0.85      2000\n",
      "\n",
      "[[1551   56]\n",
      " [ 211  182]]\n"
     ]
    }
   ],
   "source": [
    "#train, evaluate random forest\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b825ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1607\n",
      "           1       0.75      0.49      0.59       393\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.72      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "[[1543   64]\n",
      " [ 201  192]]\n"
     ]
    }
   ],
   "source": [
    "#train, evaluate gradient boosting\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(confusion_matrix(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31287ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances:\n",
      " [0.14421398 0.01925823 0.2397831  0.08242715 0.13861331 0.13025456\n",
      " 0.01872239 0.04110996 0.14663846 0.02571053 0.01326835]\n",
      "Gradient Boosting Feature Importances:\n",
      " [0.01990865 0.01380541 0.38336523 0.00359955 0.08563951 0.30521879\n",
      " 0.00058077 0.11980215 0.02052282 0.04706428 0.00049284]\n"
     ]
    }
   ],
   "source": [
    "#RF and GB\n",
    "print(\"Random Forest Feature Importances:\\n\", rf_clf.feature_importances_)\n",
    "print(\"Gradient Boosting Feature Importances:\\n\", gb_clf.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
